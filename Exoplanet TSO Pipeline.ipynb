{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from astroML.plotting          import hist\n",
    "from astropy.io                import fits\n",
    "from astropy.modeling          import models, fitting\n",
    "from datetime                  import datetime\n",
    "from image_registration        import cross_correlation_shifts\n",
    "from glob                      import glob\n",
    "from matplotlib.ticker         import MaxNLocator\n",
    "from matplotlib                import style\n",
    "from os                        import listdir\n",
    "from pandas                    import DataFrame, read_csv, read_pickle, scatter_matrix\n",
    "from photutils                 import CircularAperture, CircularAnnulus, aperture_photometry, findstars\n",
    "from least_asymmetry           import actr, moments, fitgaussian\n",
    "from pylab                     import ion, gcf, sort, linspace, indices, median, mean, std, empty, figure, transpose, ceil\n",
    "from pylab                     import concatenate, pi, sqrt, ones, diag, inf, rcParams, isnan, isfinite, array, nanmax\n",
    "from numpy                     import min as npmin, max as npmax, zeros, arange, sum, float, isnan, hstack\n",
    "from numpy                     import int32 as npint, round as npround, nansum as sum, nanstd as std\n",
    "from seaborn                   import *\n",
    "from scipy.special             import erf\n",
    "from scipy                     import stats\n",
    "from sklearn.externals         import joblib\n",
    "from socket                    import gethostname\n",
    "from statsmodels.robust        import scale\n",
    "from statsmodels.nonparametric import kde\n",
    "from sys                       import exit\n",
    "from time                      import time, localtime\n",
    "\n",
    "from numpy                     import zeros, nanmedian as median, nanmean as mean, nan\n",
    "from sys                       import exit\n",
    "from sklearn.externals         import joblib\n",
    "from least_asymmetry           import actr\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rcParams['image.interpolation'] = 'None'\n",
    "rcParams['image.cmap']          = 'Blues_r'\n",
    "rcParams['axes.grid']           = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir = '/path/to/fits/files/main/directory/'\n",
    "fitsFileDir = 'path/to/fits/subdirectories/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fitsFilenames = glob(dataDir + fitsFileDir + '*slp.fits')\n",
    "fitsFilenames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load All of the Data\n",
    "==="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_julian_date_from_gregorian_date(*date):\n",
    "    \"\"\"gd2jd.py converts a UT Gregorian date to Julian date.\n",
    "    \n",
    "    Functions for JD <-> GD conversion, \n",
    "      courtesy of Ian Crossfield at \n",
    "      http://www.astro.ucla.edu/~ianc/python/_modules/date.html\n",
    "    \n",
    "    Downloaded from Marshall Perrin Github at\n",
    "        https://github.com/mperrin/misc_astro/blob/master/idlastro_ports/gd2jd.py\n",
    "    \n",
    "    Usage: gd2jd.py (2009, 02, 25, 01, 59, 59)\n",
    "\n",
    "    To get the current Julian date:\n",
    "        import time\n",
    "        gd2jd(time.gmtime())\n",
    "\n",
    "    Hours, minutes and/or seconds can be omitted -- if so, they are\n",
    "    assumed to be zero.\n",
    "\n",
    "    Year and month are converted to type INT, but all others can be\n",
    "    type FLOAT (standard practice would suggest only the final element\n",
    "    of the date should be float)\n",
    "    \"\"\"\n",
    "    verbose=False\n",
    "    if verbose: print(date)\n",
    "\n",
    "    date = list(date)\n",
    "    \n",
    "    if len(date)<3:\n",
    "        print(\"You must enter a date of the form (2009, 02, 25)!\")\n",
    "        return -1\n",
    "    elif len(date)==3:\n",
    "        for ii in range(3): date.append(0)\n",
    "    elif len(date)==4:\n",
    "        for ii in range(2): date.append(0)\n",
    "    elif len(date)==5:\n",
    "        date.append(0)\n",
    "\n",
    "    yyyy = int(date[0])\n",
    "    mm = int(date[1])\n",
    "    dd = float(date[2])\n",
    "    hh = float(date[3])\n",
    "    min = float(date[4])\n",
    "    sec = float(date[5])\n",
    "\n",
    "    UT=hh+min/60+sec/3600\n",
    "\n",
    "\n",
    "    total_seconds=hh*3600+min*60+sec\n",
    "    fracday=total_seconds/86400\n",
    "\n",
    "    if (100*yyyy+mm-190002.5)>0:\n",
    "        sig=1\n",
    "    else:\n",
    "        sig=-1\n",
    "\n",
    "    JD = 367*yyyy - int(7*(yyyy+int((mm+9)/12))/4) + int(275*mm/9) + dd + 1721013.5 + UT/24 - 0.5*sig +0.5\n",
    "\n",
    "    months=[\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \n",
    "                \"September\", \"October\", \"November\", \"December\"]\n",
    "\n",
    "    # Now calculate the fractional year. Do we have a leap year?\n",
    "    daylist=[31,28,31,30,31,30,31,31,30,31,30,31]\n",
    "    daylist2=[31,29,31,30,31,30,31,31,30,31,30,31]\n",
    "    if (yyyy%4 != 0):\n",
    "        days=daylist2\n",
    "    elif (yyyy%400 == 0):\n",
    "        days=daylist2\n",
    "    elif (yyyy%100 == 0):\n",
    "        days=daylist\n",
    "    else:\n",
    "        days=daylist2\n",
    "\n",
    "    daysum=0\n",
    "    for y in range(mm-1):\n",
    "        daysum=daysum+days[y]\n",
    "    daysum=daysum+dd-1+UT/24\n",
    "\n",
    "    if days[1]==29:\n",
    "        fracyear=yyyy+daysum/366\n",
    "    else:\n",
    "        fracyear=yyyy+daysum/365\n",
    "    if verbose: \n",
    "        print(yyyy,mm,dd,hh,min,sec)\n",
    "        print(\"UT=\"+UT)\n",
    "        print(\"Fractional day: %f\" % fracday)\n",
    "        print(\"\\n\"+months[mm-1]+\" %i, %i, %i:%i:%i UT = JD %f\" % (dd, yyyy, hh, min, sec, JD), end= \" \")\n",
    "        print(\" = \" + fracyear+\"\\n\")\n",
    "    \n",
    "    return JD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_julian_date_from_header(header):\n",
    "    # These are specific to STScI standards -- may vary on the ground\n",
    "    fitsDate    = header['DATE-OBS']\n",
    "    startTimeStr= header['TIME-OBS']\n",
    "    endTimeStr  = header['TIME-END']\n",
    "    \n",
    "    yyyy, mm , dd   = fitsDate.split('-')\n",
    "    \n",
    "    hh1 , mn1, ss1  = array(startTimeStr.split(':')).astype(float)\n",
    "    hh2 , mn2, ss2  = array(endTimeStr.split(':')).astype(float)\n",
    "    \n",
    "    yyyy  = float(yyyy)\n",
    "    mm    = float(mm)\n",
    "    dd    = float(dd)\n",
    "    \n",
    "    hh1   = float(hh1)\n",
    "    mn1   = float(mn1)\n",
    "    ss1   = float(ss1)\n",
    "    \n",
    "    hh2   = float(hh2)\n",
    "    mn2   = float(mn2)\n",
    "    ss2   = float(ss2)\n",
    "    \n",
    "    startDate   = get_julian_date_from_gregorian_date(yyyy,mm,dd,hh1,mn1,ss1)\n",
    "    endDate     = get_julian_date_from_gregorian_date(yyyy,mm,dd,hh2,mn2,ss2)\n",
    "\n",
    "    return startDate, endDate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flux_weighted_centroid(image, ypos, xpos, bSize = 7):\n",
    "    '''\n",
    "        Flux-weighted centroiding (Knutson et al. 2008)\n",
    "        xpos and ypos are the rounded pixel positions of the star\n",
    "    '''\n",
    "    \n",
    "    ## extract a box around the star:\n",
    "    #im = a[ypos-bSize:ypos+bSize, xpos-bSize:xpos+bSize].copy()\n",
    "    subImage = image[ypos-bSize:ypos+bSize, xpos-bSize:xpos+bSize].transpose().copy()\n",
    "\n",
    "    y,x = 0,1\n",
    "    \n",
    "    ydim = subImage.shape[y]\n",
    "    xdim = subImage.shape[x]\n",
    "    \n",
    "    ## add up the flux along x and y\n",
    "    xflux = zeros(xdim)\n",
    "    xrng  = arange(xdim)\n",
    "    \n",
    "    yflux = zeros(ydim)\n",
    "    yrng  = arange(ydim)\n",
    "    \n",
    "    for i in range(xdim):\n",
    "        xflux[i] = sum(subImage[i,:])\n",
    "\n",
    "    for j in range(ydim):\n",
    "        yflux[j] = sum(subImage[:,j])\n",
    "\n",
    "    ## get the flux weighted average position:\n",
    "    ypeak = sum(yflux * yrng) / sum(yflux) + ypos - float(bSize)\n",
    "    xpeak = sum(xflux * xrng) / sum(xflux) + xpos - float(bSize)\n",
    "\n",
    "    return (ypeak, xpeak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fit_gauss(subFrameNow, xinds, yinds, initParams, print_compare=False):\n",
    "    # initParams = (height, x, y, width_x, width_y, offset)\n",
    "    fit_lvmq = fitting.LevMarLSQFitter()\n",
    "    model0  = models.Gaussian2D(amplitude=initParams[0], x_mean=initParams[1], y_mean=initParams[2], \n",
    "                                x_stddev=initParams[3], y_stddev=initParams[4], theta=0.0) + \\\n",
    "              models.Const2D(amplitude=initParams[5])\n",
    "    \n",
    "    model1  = fit_lvmq(model0, xinds, yinds, subFrameNow)\n",
    "    model1  = fit_lvmq(model1, xinds, yinds, subFrameNow)\n",
    "    \n",
    "    if print_compare:\n",
    "        print(model1.amplitude_0 - initParams[0], end=\" \")\n",
    "        print(model1.x_mean_0    - initParams[1], end=\" \")\n",
    "        print(model1.y_mean_0    - initParams[2], end=\" \")\n",
    "        print(model1.x_stddev_0  - initParams[3], end=\" \")\n",
    "        print(model1.y_stddev_0  - initParams[4], end=\" \")\n",
    "        print(model1.amplitude_1 - initParams[5])\n",
    "    \n",
    "    return model1.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class wanderer(object):\n",
    "    print('\\n\\n** Not all who wander are lost **\\n\\n')\n",
    "    def __init__(self, fitsFileDir = './', filetype = 'slp.fits', \n",
    "                 yguess=None, xguess=None, npix=10, method='mean'):\n",
    "        \n",
    "        y,x = 0,1\n",
    "        \n",
    "        if method == 'mean':\n",
    "            self.metric  = mean\n",
    "        elif method == 'median':\n",
    "            self.metric  = median\n",
    "        else:\n",
    "            raise Exception(\"`method` must be from the list ['mean', 'median']\")\n",
    "        \n",
    "        self.fitsFileDir  = fitsFileDir\n",
    "        self.fitsFilenames = glob(self.fitsFileDir + '/*' + filetype)\n",
    "        self.nSlopeFiles  = len(self.fitsFilenames)\n",
    "        \n",
    "        if self.nSlopeFiles == 0:\n",
    "            print('Pipeline found no Files in ' + self.fitsFileDir + ' of type /*' + filetype)\n",
    "            exit(-1)\n",
    "        \n",
    "        self.centering_df   = DataFrame()\n",
    "        self.background_df  = DataFrame()\n",
    "        self.flux_TSO_df    = DataFrame()\n",
    "        self.noise_TSO_df   = DataFrame()\n",
    "        \n",
    "        testfits            = fits.open(self.fitsFilenames[0])[0]\n",
    "        \n",
    "        self.imageCube      = np.zeros((self.nSlopeFiles, testfits.data[0].shape[0], testfits.data[0].shape[1]))\n",
    "        self.noiseCube      = np.zeros((self.nSlopeFiles, testfits.data[0].shape[0], testfits.data[0].shape[1]))\n",
    "        self.timeCube       = np.zeros(self.nSlopeFiles)\n",
    "        \n",
    "        if yguess == None:\n",
    "            self.yguess = self.imageCube.shape[y]//2\n",
    "        else:\n",
    "            self.yguess = yguess\n",
    "        if xguess == None:\n",
    "            self.xguess = self.imageCube.shape[x]//2\n",
    "        else:\n",
    "            self.xguess = xguess\n",
    "        \n",
    "        self.npix = npix\n",
    "        \n",
    "    def load_data_from_fits_files(self):\n",
    "        \n",
    "        nGroups        = len(self.fitsFilenames)\n",
    "        for kframe, fname in enumerate(self.fitsFilenames):\n",
    "            \n",
    "            fitsNow = fits.open(fname)\n",
    "            \n",
    "            self.imageCube[kframe] = fitsNow[0].data[0]\n",
    "            self.noiseCube[kframe] = fitsNow[0].data[1]\n",
    "            \n",
    "            # re-write these 4 lines into `get_julian_date_from_header`\n",
    "            day2sec        = 86400.\n",
    "            startJD,endJD     = get_julian_date_from_header(fitsNow[0].header)\n",
    "            timeSpan          = (endJD - startJD)*day2sec/nGroups\n",
    "            self.timeCube[kframe]  = startJD  + timeSpan*(kframe+0.5) / day2sec - 2450000.\n",
    "            \n",
    "            del fitsNow[0].data\n",
    "            fitsNow.close()\n",
    "            del fitsNow\n",
    "    \n",
    "    def load_data_from_save_files(self, savefiledir=None, saveFileNameHeader=None, saveFileType='.pickle.save'):\n",
    "        \n",
    "        if saveFileNameHeader is None:\n",
    "            raise Exception('`saveFileNameHeader` should be the beginning of each save file name')\n",
    "        \n",
    "        if savefiledir is None:\n",
    "            savefiledir = './'\n",
    "        \n",
    "        print('Loading from Master Files')\n",
    "        self.centering_df   = read_pickle(savefiledir  + saveFileNameHeader + '_centering_dataframe'  + saveFileType)\n",
    "        self.background_df  = read_pickle(savefiledir + saveFileNameHeader + '_background_dataframe' + saveFileType)\n",
    "        self.flux_TSO_df    = read_pickle(savefiledir   + saveFileNameHeader + '_flux_TSO_dataframe'   + saveFileType)\n",
    "        \n",
    "        try:\n",
    "            self.noise_TSO_df   = read_pickle(savefiledir   + saveFileNameHeader + '_noise_TSO_dataframe'   + saveFileType)\n",
    "        except:\n",
    "            self.noise_TSO_df   = None\n",
    "        \n",
    "        self.imageCube        = joblib.load(savefiledir  + saveFileNameHeader + '_image_cube_array' + saveFileType)\n",
    "        self.noiseCube        = joblib.load(savefiledir  + saveFileNameHeader + '_noise_cube_array' + saveFileType)\n",
    "        self.timeCube         = joblib.load(savefiledir  + saveFileNameHeader + '_time_cube_array'  + saveFileType)\n",
    "        \n",
    "        self.imageBadPixMasks = joblib.load(savefiledir  + saveFileNameHeader + '_image_bad_pix_cube_array' + saveFileType)\n",
    "        \n",
    "        self.save_dict        = joblib.load(savefiledir + saveFileNameHeader + '_save_dict' + saveFileType)\n",
    "        \n",
    "        print('Assigning Parts of `self.save_dict` to individual data structures')\n",
    "        for key in self.save_dict.keys():\n",
    "            exec(\"self.\" + key + \" = self.save_dict['\" + key + \"']\")\n",
    "        \n",
    "        # self.fitsFileDir              = self.save_dict['fitsFileDir']\n",
    "        # self.fitsFilenames             = self.save_dict['fitsFilenames']\n",
    "\n",
    "        # self.background_Annulus       = self.save_dict['background_Annulus']\n",
    "        # self.background_CircleMask    = self.save_dict['background_CircleMask']\n",
    "        # self.background_GaussMoment   = self.save_dict['background_GaussMoment']\n",
    "        # self.background_GaussianFit   = self.save_dict['background_GaussianFit']\n",
    "        # self.background_KDEUniv       = self.save_dict['background_KDEUniv']\n",
    "        # self.background_MedianMask    = self.save_dict['background_MedianMask']\n",
    "        # self.centering_FluxWeight     = self.save_dict['centering_FluxWeight']\n",
    "        # self.centering_GaussianFit    = self.save_dict['centering_GaussianFit']\n",
    "        # self.centering_GaussianMoment = self.save_dict['centering_GaussianMoment']\n",
    "        # self.centering_LeastAsym      = self.save_dict['centering_LeastAsym']\n",
    "        # self.fitsFileDir              = self.save_dict['fitsFileDir']\n",
    "        # self.heights_GaussianFit      = self.save_dict['heights_GaussianFit']\n",
    "        # self.heights_GaussianMoment   = self.save_dict['heights_GaussianMoment']\n",
    "        # # self.imageCubeMAD             = self.save_dict['imageCubeMAD']\n",
    "        # # self.imageCubeMedian          = self.save_dict['imageCubeMedian']\n",
    "        # self.fitsFilenames             = self.save_dict['fitsFilenames']\n",
    "        # self.widths_GaussianFit       = self.save_dict['widths_GaussianFit']\n",
    "        # self.widths_GaussianMoment    = self.save_dict['widths_GaussianMoment']\n",
    "    \n",
    "    def save_data_to_save_files(self, savefiledir=None, saveFileNameHeader=None, saveFileType='.pickle.save'):\n",
    "        \n",
    "        if saveFileNameHeader is None:\n",
    "            raise Exception('`saveFileNameHeader` should be the beginning of each save file name')\n",
    "        \n",
    "        if savefiledir is None:\n",
    "            savefiledir = './'\n",
    "        \n",
    "        date            = localtime()\n",
    "        \n",
    "        year            = date.tm_year\n",
    "        month           = date.tm_mon\n",
    "        day             = date.tm_mday\n",
    "        \n",
    "        hour            = date.tm_hour\n",
    "        minute          = date.tm_min\n",
    "        sec             = date.tm_sec\n",
    "        \n",
    "        date_string     = '_' + str(year) + '-' + str(month)  + '-' + str(day) + '_' + \\\n",
    "                                str(hour) + 'h' + str(minute) + 'm' + str(sec) + 's'\n",
    "        \n",
    "        saveFileTypeBak = date_string + saveFileType\n",
    "        \n",
    "        initiate_save_dict()\n",
    "        \n",
    "        print('Saving to Master File -- Overwriting Previous Master')\n",
    "        self.centering_df.to_pickle(savefiledir  + saveFileNameHeader + '_centering_dataframe'  + saveFileType)\n",
    "        self.background_df.to_pickle(savefiledir + saveFileNameHeader + '_background_dataframe' + saveFileType)\n",
    "        self.flux_TSO_df.to_pickle(savefiledir   + saveFileNameHeader + '_flux_TSO_dataframe'   + saveFileType)\n",
    "        \n",
    "        joblib.dump(self.imageCube, savefiledir  + saveFileNameHeader + '_image_cube_array' + saveFileType)\n",
    "        joblib.dump(self.noiseCube, savefiledir  + saveFileNameHeader + '_noise_cube_array' + saveFileType)\n",
    "        joblib.dump(self.timeCube , savefiledir  + saveFileNameHeader + '_time_cube_array'  + saveFileType)\n",
    "        \n",
    "        joblib.dump(self.imageBadPixMasks, savefiledir  + saveFileNameHeader + '_image_bad_pix_cube_array' + saveFileType)\n",
    "        \n",
    "        joblib.dump(self.save_dict, savefiledir + saveFileNameHeader + '_save_dict' + saveFileType)\n",
    "        \n",
    "        print('Saving to New TimeStamped File -- These Tend to Pile Up!')\n",
    "        self.centering_df.to_pickle(savefiledir  + saveFileNameHeader + '_centering_dataframe'  + saveFileTypeBak)\n",
    "        self.background_df.to_pickle(savefiledir + saveFileNameHeader + '_background_dataframe' + saveFileTypeBak)\n",
    "        self.flux_TSO_df.to_pickle(savefiledir   + saveFileNameHeader + '_flux_TSO_dataframe'   + saveFileTypeBak)\n",
    "        \n",
    "        joblib.dump(self.imageCube, savefiledir  + saveFileNameHeader + '_image_cube_array' + saveFileTypeBak)\n",
    "        joblib.dump(self.noiseCube, savefiledir  + saveFileNameHeader + '_noise_cube_array' + saveFileTypeBak)\n",
    "        joblib.dump(self.timeCube , savefiledir  + saveFileNameHeader + '_time_cube_array'  + saveFileTypeBak)\n",
    "        \n",
    "        joblib.dump(self.imageBadPixMasks, savefiledir  + saveFileNameHeader + '_image_bad_pix_cube_array' + saveFileTypeBak)\n",
    "        \n",
    "        joblib.dump(self.save_dict, savefiledir + saveFileNameHeader + '_save_dict' + saveFileTypeBak)\n",
    "    \n",
    "    def initiate_save_dict(self):\n",
    "        \n",
    "        self.save_dict  = {} # DataFrame() -- test if this works later\n",
    "        \n",
    "        self.save_dict['fitsFileDir']               = self.fitsFileDir\n",
    "        self.save_dict['fitsFilenames']              = self.fitsFilenames\n",
    "        \n",
    "        self.save_dict['background_Annulus']        = self.background_Annulus\n",
    "        self.save_dict['background_CircleMask']     = self.background_CircleMask\n",
    "        self.save_dict['background_GaussMoment']    = self.background_GaussMoment\n",
    "        self.save_dict['background_GaussianFit']    = self.background_GaussianFit\n",
    "        self.save_dict['background_KDEUniv']        = self.background_KDEUniv\n",
    "        self.save_dict['background_MedianMask']     = self.background_MedianMask\n",
    "        self.save_dict['centering_FluxWeight']      = self.centering_FluxWeight\n",
    "        self.save_dict['centering_GaussianFit']     = self.centering_GaussianFit\n",
    "        self.save_dict['centering_GaussianMoment']  = self.centering_GaussianMoment\n",
    "        self.save_dict['centering_LeastAsym']       = self.centering_LeastAsym\n",
    "        self.save_dict['fitsFileDir']               = self.fitsFileDir\n",
    "        self.save_dict['heights_GaussianFit']       = self.heights_GaussianFit\n",
    "        self.save_dict['heights_GaussianMoment']    = self.heights_GaussianMoment\n",
    "        # self.save_dict['']                          = self.imageCubeMAD\n",
    "        # self.save_dict['']                          = self.imageCubeMedian\n",
    "        self.save_dict['method']                    = self.method\n",
    "        self.save_dict['npix']                      = self.npix\n",
    "        self.save_dict['fitsFilenames']              = self.fitsFilenames\n",
    "        self.save_dict['yguess']                    = self.yguess\n",
    "        self.save_dict['xguess']                    = self.xguess\n",
    "        self.save_dict['widths_GaussianFit']        = self.widths_GaussianFit\n",
    "        self.save_dict['widths_GaussianMoment']     = self.widths_GaussianMoment\n",
    "    \n",
    "    def copy_instance(self):\n",
    "        \n",
    "        temp = wanderer()\n",
    "        temp.saveFileNameHeader = self.saveFileNameHeader\n",
    "        temp.savefiledir = self.savefiledir\n",
    "        \n",
    "        temp.centering_df = self.centering_df\n",
    "        temp.background_df = self.background_df\n",
    "        temp.flux_TSO_df = self.flux_TSO_df\n",
    "        temp.noise_TSO_df = self.noise_TSO_df\n",
    "        \n",
    "        temp.imageCube = self.imageCube\n",
    "        temp.noiseCube = self.noiseCube\n",
    "        temp.timeCube = self.timeCube\n",
    "        \n",
    "        temp.imageBadPixMasks = self.imageBadPixMasks = joblib.load(savefiledir  + saveFileNameHeader + '_image_bad_pix_cube_array' + saveFileType)\n",
    "        \n",
    "        print('Assigning Parts of `temp.save_dict` to from `self.save_dict`')\n",
    "        temp.save_dict = self.save_dict\n",
    "        for key in self.save_dict.keys():\n",
    "            exec(\"temp.\" + key + \" = temp.save_dict['\" + key + \"']\")\n",
    "        \n",
    "        # temp.fitsFileDir              = temp.save_dict['fitsFileDir']\n",
    "        # temp.fitsFilenames             = temp.save_dict['fitsFilenames']\n",
    "\n",
    "        # temp.background_Annulus       = temp.save_dict['background_Annulus']\n",
    "        # temp.background_CircleMask    = temp.save_dict['background_CircleMask']\n",
    "        # temp.background_GaussMoment   = temp.save_dict['background_GaussMoment']\n",
    "        # temp.background_GaussianFit   = temp.save_dict['background_GaussianFit']\n",
    "        # temp.background_KDEUniv       = temp.save_dict['background_KDEUniv']\n",
    "        # temp.background_MedianMask    = temp.save_dict['background_MedianMask']\n",
    "        # temp.centering_FluxWeight     = temp.save_dict['centering_FluxWeight']\n",
    "        # temp.centering_GaussianFit    = temp.save_dict['centering_GaussianFit']\n",
    "        # temp.centering_GaussianMoment = temp.save_dict['centering_GaussianMoment']\n",
    "        # temp.centering_LeastAsym      = temp.save_dict['centering_LeastAsym']\n",
    "        # temp.fitsFileDir              = temp.save_dict['fitsFileDir']\n",
    "        # temp.heights_GaussianFit      = temp.save_dict['heights_GaussianFit']\n",
    "        # temp.heights_GaussianMoment   = temp.save_dict['heights_GaussianMoment']\n",
    "        # # temp.imageCubeMAD             = temp.save_dict['imageCubeMAD']\n",
    "        # # temp.imageCubeMedian          = temp.save_dict['imageCubeMedian']\n",
    "        # temp.fitsFilenames             = temp.save_dict['fitsFilenames']\n",
    "        # temp.widths_GaussianFit       = temp.save_dict['widths_GaussianFit']\n",
    "        # temp.widths_GaussianMoment    = temp.save_dict['widths_GaussianMoment']\n",
    "    \n",
    "    def find_bad_pixels(self, nSig=5):\n",
    "        # we chose 5 arbitrarily, but from experience\n",
    "        self.imageCubeMedian  = median(self.imageCube,axis=0)\n",
    "        self.imageCubeMAD     = scale.mad(self.imageCube,axis=0)\n",
    "        \n",
    "        self.imageBadPixMasks = abs(self.imageCube - self.imageCubeMedian) > nSig*self.imageCubeMAD\n",
    "        \n",
    "        print(\"There are \" + str(sum(self.imageBadPixMasks)) + \" 'Hot' Pixels\")\n",
    "        \n",
    "        self.imageCube[self.imageBadPixMasks] = nan\n",
    "    \n",
    "    def fit_gaussian_fitting_centering(self, method='la', initc='fw', print_compare=False):\n",
    "        y,x = 0,1\n",
    "        \n",
    "        yinds0, xinds0 = indices(self.imageCube[0].shape)\n",
    "        \n",
    "        ylower = self.yguess - self.npix\n",
    "        yupper = self.yguess + self.npix\n",
    "        xlower = self.xguess - self.npix\n",
    "        xupper = self.xguess + self.npix\n",
    "        \n",
    "        ylower, xlower, yupper, xupper = np.int32([ylower, xlower, yupper, xupper])\n",
    "        \n",
    "        yinds = yinds0[ylower:yupper, xlower:xupper]\n",
    "        xinds = xinds0[ylower:yupper, xlower:xupper]\n",
    "        \n",
    "        self.centering_GaussianFit    = zeros((self.imageCube.shape[0], 2))\n",
    "        self.centering_GaussianMoment = zeros((self.imageCube.shape[0], 2))\n",
    "        self.widths_GaussianFit       = zeros((self.imageCube.shape[0], 2))\n",
    "        self.widths_GaussianMoment    = zeros((self.imageCube.shape[0], 2))\n",
    "        \n",
    "        self.heights_GaussianFit      = zeros(self.imageCube.shape[0])\n",
    "        self.heights_GaussianMoment   = zeros(self.imageCube.shape[0])\n",
    "        # self.rotation_GaussianFit     = zeros(self.imageCube.shape[0])\n",
    "        self.background_GaussMoment   = zeros(self.imageCube.shape[0])\n",
    "        self.background_GaussianFit   = zeros(self.imageCube.shape[0])\n",
    "        \n",
    "        for kframe in range(self.imageCube.shape[0]):\n",
    "            subFrameNow = self.imageCube[kframe][ylower:yupper, xlower:xupper]\n",
    "            subFrameNow[isnan(subFrameNow)] = median(~isnan(subFrameNow))\n",
    "            \n",
    "            cmom    = np.array(moments(subFrameNow))  # H, Xc, Yc, Xs, Ys, O\n",
    "            \n",
    "            if method == 'ap':\n",
    "                if initc == 'fw' and self.centering_FluxWeight.sum():\n",
    "                    FWCNow    = self.centering_FluxWeight[kframe]\n",
    "                    FWCNow[y] = FWCNow[y] - ylower\n",
    "                    FWCNow[x] = FWCNow[x] - xlower\n",
    "                    gaussI    = hstack([cmom[0], FWCNow, cmom[3:]])\n",
    "                if initc == 'cm':\n",
    "                    gaussI  = hstack([cmom[0], cmom[1], cmom[2], cmom[3:]])\n",
    "                \n",
    "                gaussP  = fit_gauss(subFrameNow, xinds, yinds, gaussI) # H, Xc, Yc, Xs, Ys, Th, O\n",
    "            \n",
    "            if method == 'la':\n",
    "                gaussP  = fitgaussian(subFrameNow)#, xinds, yinds, np.copy(cmom)) # H, Xc, Yc, Xs, Ys, Th, O\n",
    "            \n",
    "            self.centering_GaussianFit[kframe][x]     = gaussP[1] + xlower\n",
    "            self.centering_GaussianFit[kframe][y]     = gaussP[2] + ylower\n",
    "            self.centering_GaussianMoment[kframe][x]  = cmom[1]   + xlower\n",
    "            self.centering_GaussianMoment[kframe][y]  = cmom[2]   + ylower\n",
    "            \n",
    "            self.widths_GaussianFit[kframe][x]        = gaussP[3]\n",
    "            self.widths_GaussianFit[kframe][y]        = gaussP[4]\n",
    "            self.widths_GaussianMoment[kframe][x]     = cmom[3]\n",
    "            self.widths_GaussianMoment[kframe][y]     = cmom[4]\n",
    "            \n",
    "            self.heights_GaussianFit[kframe]          = gaussP[0]\n",
    "            self.heights_GaussianMoment[kframe]       = cmom[0]\n",
    "            \n",
    "            self.background_GaussianFit[kframe]       = gaussP[5]\n",
    "            self.background_GaussMoment[kframe]       = cmom[5]\n",
    "            \n",
    "            if print_compare:\n",
    "                print('Finished Frame ' + str(kframe) + ' with Yc = ' + \\\n",
    "                      str(self.centering_GaussianFit[kframe][y] - self.centering_GaussianMoment[kframe][y]) + '; Xc = ' + \\\n",
    "                      str(self.centering_GaussianFit[kframe][x] - self.centering_GaussianMoment[kframe][x]))\n",
    "            \n",
    "            del gaussP, cmom\n",
    "        \n",
    "        self.centering_df = DataFrame()\n",
    "        self.centering_df['Gaussian_Fit_Y_Centers'] = self.centering_GaussianFit.T[y]\n",
    "        self.centering_df['Gaussian_Fit_X_Centers'] = self.centering_GaussianFit.T[x]\n",
    "        self.centering_df['Gaussian_Mom_Y_Centers'] = self.centering_GaussianFit.T[y]\n",
    "        self.centering_df['Gaussian_Mom_X_Centers'] = self.centering_GaussianFit.T[x]\n",
    "        \n",
    "        self.centering_df['Gaussian_Fit_Y_Widths']  = self.widths_GaussianFit.T[y]\n",
    "        self.centering_df['Gaussian_Fit_X_Widths']  = self.widths_GaussianFit.T[x]\n",
    "        self.centering_df['Gaussian_Mom_Y_Widths']  = self.widths_GaussianMoment.T[y]\n",
    "        self.centering_df['Gaussian_Mom_X_Widths']  = self.widths_GaussianMoment.T[x]\n",
    "        \n",
    "        self.centering_df['Gaussian_Fit_Heights']   = self.heights_GaussianFit\n",
    "        self.centering_df['Gaussian_Mom_Heights']   = self.heights_GaussianMoment\n",
    "        \n",
    "        self.centering_df['Gaussian_Fit_Offset']    = self.background_GaussianFit\n",
    "        self.centering_df['Gaussian_Mom_Offset']    = self.background_GaussMoment\n",
    "        \n",
    "        # self.centering_df['Gaussian_Fit_Rotation']    = self.rotation_GaussianFit\n",
    "    \n",
    "    def fit_flux_weighted_centering(self):\n",
    "        y,x = 0,1\n",
    "        \n",
    "        yinds0, xinds0 = indices(self.imageCube[0].shape)\n",
    "        \n",
    "        ylower = self.yguess - self.npix\n",
    "        yupper = self.yguess + self.npix\n",
    "        xlower = self.xguess - self.npix\n",
    "        xupper = self.xguess + self.npix\n",
    "        \n",
    "        ylower, xlower, yupper, xupper = np.int32([ylower, xlower, yupper, xupper])\n",
    "        \n",
    "        yinds = yinds0[ylower:yupper, xlower:xupper]\n",
    "        xinds = xinds0[ylower:yupper, xlower:xupper]\n",
    "        \n",
    "        nFWCParams                = 2 # Xc, Yc\n",
    "        self.centering_FluxWeight = np.zeros((self.nSlopeFiles, nFWCParams))\n",
    "        \n",
    "        for kframe in range(self.nSlopeFiles):\n",
    "            subFrameNow = self.imageCube[kframe][ylower:yupper, xlower:xupper]\n",
    "            subFrameNow[isnan(subFrameNow)] = median(~isnan(subFrameNow))\n",
    "            \n",
    "            self.centering_FluxWeight[kframe] = flux_weighted_centroid(self.imageCube[kframe], \n",
    "                                                                       self.yguess, self.xguess, bSize = 7)\n",
    "            self.centering_FluxWeight[kframe] = self.centering_FluxWeight[kframe][::-1]\n",
    "        \n",
    "        self.centering_df['FluxWeighted_Y_Centers'] = self.centering_FluxWeight.T[y]\n",
    "        self.centering_df['FluxWeighted_X_Centers'] = self.centering_FluxWeight.T[x]\n",
    "\n",
    "    def fit_least_asymmetry_centering(self):\n",
    "        \n",
    "        y,x = 0,1\n",
    "        \n",
    "        yinds0, xinds0 = indices(self.imageCube[0].shape)\n",
    "        \n",
    "        ylower = self.yguess - self.npix\n",
    "        yupper = self.yguess + self.npix\n",
    "        xlower = self.xguess - self.npix\n",
    "        xupper = self.xguess + self.npix\n",
    "        \n",
    "        ylower, xlower, yupper, xupper = np.int32([ylower, xlower, yupper, xupper])\n",
    "        \n",
    "        yinds = yinds0[ylower:yupper, xlower:xupper]\n",
    "        xinds = xinds0[ylower:yupper, xlower:xupper]\n",
    "        \n",
    "        nAsymParams = 2 # Xc, Yc\n",
    "        self.centering_LeastAsym  = np.zeros((self.nSlopeFiles, nAsymParams))\n",
    "        \n",
    "        for kframe in range(self.nSlopeFiles):\n",
    "            # print(kframe, ylower,yupper, xlower,xupper) # (0 143 163 150 170)\n",
    "            subFrameNow = self.imageCube[kframe][ylower:yupper, xlower:xupper]\n",
    "            subFrameNow[isnan(subFrameNow)]   = median(subFrameNow)\n",
    "            \n",
    "            center_asym = actr(self.imageCube[kframe], [self.yguess, self.xguess])[0]\n",
    "            try:\n",
    "                self.centering_LeastAsym[kframe]  = center_asym[::-1]\n",
    "            except:\n",
    "                self.centering_LeastAsym[kframe]  = [nan,nan]\n",
    "        \n",
    "        self.centering_df['LeastAsymmetry_Y_Centers'] = self.centering_FluxWeight.T[y]\n",
    "        self.centering_df['LeastAsymmetry_X_Centers'] = self.centering_FluxWeight.T[x]\n",
    "\n",
    "    def fit_all_centering(self):\n",
    "        print('Fit for Gaussian Fitting & Gaussian Moment Centers\\n')\n",
    "        self.fit_gaussian_fitting_centering()\n",
    "        print('Fit for Flux Weighted Centers\\n')\n",
    "        self.fit_flux_weighted_centering()\n",
    "        print('Fit for Least Asymmetry Centers\\n')\n",
    "        self.fit_least_asymmetry_centering()\n",
    "    \n",
    "    def measure_effective_width(self):\n",
    "        self.effective_widths = self.imageCube.sum(axis=(1,2))**2. / ((self.imageCube)**2).sum(axis=(1,2))\n",
    "        self.centering_df['Effective_Widths'] = self.effective_widths\n",
    "    \n",
    "    def measure_background_circle_masked(self, aperRad=None, method='mean'):\n",
    "        \"\"\"\n",
    "            Assigning all zeros in the mask to NaNs because the `mean` and `median` \n",
    "                functions are set to `nanmean` functions, which will skip all NaNs\n",
    "        \"\"\"\n",
    "        \n",
    "        if aperRad is None:\n",
    "            if 'wlp' in self.fitsFilenames[0].lower():\n",
    "                aperRad = 100\n",
    "            else:\n",
    "                aperRad = 10\n",
    "        \n",
    "        medianCenter   = median(self.centering_FluxWeight, axis=0)\n",
    "        aperture       = CircularAperture(medianCenter, aperRad)\n",
    "        backgroundMask = abs(aperture.get_fractions(np.ones(self.imageCube[0].shape))-1)\n",
    "        backgroundMask[backgroundMask == 0] = nan\n",
    "        \n",
    "        self.background_CircleMask = self.metric(self.imageCube*backgroundMask,axis=(1,2))\n",
    "        \n",
    "        self.background_df['CircleMask'] = self.background_CircleMask\n",
    "    \n",
    "    def measure_background_annular_mask(self, innerRad=None, outerRad=None, method='mean'):\n",
    "        \n",
    "        if innerRad is None:\n",
    "            if 'wlp' in self.fitsFilenames[0].lower():\n",
    "                innerRad = 100\n",
    "            else:\n",
    "                innerRad = 10\n",
    "        \n",
    "        if outerRad is None:\n",
    "            if 'wlp' in self.fitsFilenames[0].lower():\n",
    "                outerRad = 150\n",
    "            else:\n",
    "                outerRad = 15\n",
    "        \n",
    "        medianCenter  = median(self.centering_LeastAsym, axis=0)\n",
    "        \n",
    "        innerAperture = CircularAperture(medianCenter, innerRad).get_fractions(np.ones(self.imageCube[0].shape))\n",
    "        outerAperture = CircularAperture(medianCenter, outerRad).get_fractions(np.ones(self.imageCube[0].shape))\n",
    "                \n",
    "        backgroundMask= abs((outerAperture - innerAperture))\n",
    "        backgroundMask[backgroundMask == 0] = nan\n",
    "        \n",
    "        self.background_Annulus = self.metric(self.imageCube*backgroundMask, axis=(1,2))\n",
    "        self.background_df['AnnularMask'] = self.background_Annulus\n",
    "    \n",
    "    def measure_background_median_masked(self, aperRad=None, nSig=5, method='mean'):\n",
    "        \n",
    "        if aperRad is None:\n",
    "            if 'wlp' in self.fitsFilenames[0].lower():\n",
    "                aperRad = 100\n",
    "            else:\n",
    "                aperRad = 10\n",
    "        \n",
    "        self.background_MedianMask  = np.zeros(self.nSlopeFiles)\n",
    "        \n",
    "        medianCenter   = median(self.centering_FluxWeight, axis=0)\n",
    "        aperture       = CircularAperture(medianCenter, aperRad)\n",
    "        backgroundMask = abs(aperture.get_fractions(np.ones(self.imageCube[0].shape))-1)\n",
    "        \n",
    "        for kframe in range(self.nSlopeFiles):\n",
    "            medFrame  = median(self.imageCube[kframe])\n",
    "            madFrame  = scale.mad(self.imageCube[kframe])\n",
    "            \n",
    "            medianMask= abs(self.imageCube[kframe] - medFrame) < nSig*madFrame\n",
    "            \n",
    "            maskComb  = medianMask*backgroundMask\n",
    "            maskComb[maskComb == 0] = nan\n",
    "            \n",
    "            self.background_MedianMask[kframe] = self.metric(self.imageCube[kframe]*maskComb)\n",
    "        \n",
    "        self.background_df['MedianMask'] = self.background_MedianMask\n",
    "    \n",
    "    def measure_background_KDE_Mode(self, aperRad=None):\n",
    "        \n",
    "        if aperRad is None:\n",
    "            if 'wlp' in self.fitsFilenames[0].lower():\n",
    "                aperRad = 100\n",
    "            else:\n",
    "                aperRad = 10\n",
    "        \n",
    "        self.background_KDEUniv = np.zeros(self.nSlopeFiles)\n",
    "        \n",
    "        medianCenter   = median(self.centering_FluxWeight, axis=0)\n",
    "        aperture       = CircularAperture(medianCenter, aperRad)\n",
    "        backgroundMask = abs(aperture.get_fractions(np.ones(self.imageCube[0].shape))-1)\n",
    "        \n",
    "        for kframe in range(self.nSlopeFiles):\n",
    "            frameNow = (self.imageCube[kframe]*backgroundMask).ravel()\n",
    "            kdeFrame = kde.KDEUnivariate(frameNow[np.where(backgroundMask.ravel() != 0.0)])\n",
    "            kdeFrame.fit()\n",
    "            \n",
    "            self.background_KDEUniv[kframe] = kdeFrame.support[kdeFrame.density.argmax()]\n",
    "        \n",
    "        self.background_df['KDEUnivMask'] = self.background_KDEUniv\n",
    "    \n",
    "    def measure_all_background(self, nSig=5):\n",
    "        print('Measuring Background Using Circle Mask')\n",
    "        self.measure_background_circle_masked()\n",
    "        print('Measuring Background Using Annular Mask')\n",
    "        self.measure_background_annular_mask()\n",
    "        print('Measuring Background Using Median Mask')\n",
    "        self.measure_background_median_masked(nSig=nSig)\n",
    "        print('Measuring Background Using KDE Mode')\n",
    "        self.measure_background_KDE_Mode()\n",
    "    \n",
    "    def compute_flux_over_time(self, aperRad=None, centering='LeastAsymmetry', background='AnnularMask'):\n",
    "        y,x = 0,1\n",
    "        \n",
    "        if background not in self.background_df.columns:\n",
    "            raise Exception(\"`background` must be in\", self.background_df.columns)\n",
    "        \n",
    "        if centering not in ['Gaussian_Fit', 'Gaussian_Mom', 'FluxWeighted', 'LeastAsymmetry']:\n",
    "            raise Exception(\"`centering` must be either 'Gaussian_Fit', 'Gaussian_Mom', 'FluxWeighted', or 'LeastAsymmetry'\")\n",
    "        \n",
    "        if aperRad is None:\n",
    "            if 'wlp' in self.fitsFilenames[0].lower():\n",
    "                aperRad = 70\n",
    "            else:\n",
    "                aperRad = 3\n",
    "        \n",
    "        centering_Use = np.transpose([self.centering_df[centering + '_Y_Centers'], \n",
    "                                      self.centering_df[centering + '_X_Centers']])\n",
    "        \n",
    "        background_Use= self.background_df[background]\n",
    "        \n",
    "        flux_key_now  = centering + '_' + background+'_' + 'rad' + '_' + str(aperRad)\n",
    "        flux_TSO_now  = np.zeros(self.nSlopeFiles)\n",
    "        noise_TSO_now = np.zeros(self.nSlopeFiles)\n",
    "        for kframe in range(self.nSlopeFiles):\n",
    "            frameNow  = np.copy(self.imageCube[kframe]) - background_Use[kframe]\n",
    "            frameNow[np.isnan(frameNow)] = median(frameNow)\n",
    "            \n",
    "            noiseNow  = np.copy(self.noiseCube[kframe])**2.\n",
    "            noiseNow[np.isnan(noiseNow)] = median(noiseNow)\n",
    "            \n",
    "            aperture  = CircularAperture([centering_Use[kframe][x], centering_Use[kframe][y]], r=aperRad)\n",
    "            \n",
    "            flux_TSO_now[kframe]  = aperture_photometry(frameNow, aperture)['aperture_sum']\n",
    "            noise_TSO_now[kframe] = sqrt(aperture_photometry(noiseNow, aperture)['aperture_sum'])\n",
    "        \n",
    "        self.flux_TSO_df[flux_key_now]  = flux_TSO_now\n",
    "        self.noise_TSO_df[flux_key_now] = noise_TSO_now\n",
    "\n",
    "tm_year, tm_mon, tm_mday, tm_hour, tm_min, tm_sec, tm_wday, tm_yday, tm_isdst = localtime()\n",
    "print('Completed Class Definition at ' +\n",
    "      str(tm_year) + '-' + str(tm_mon) + '-' + str(tm_mday) + ' ' + \\\n",
    "      str(tm_hour) + 'h' + str(tm_min) + 'm' + str(tm_sec) + 's')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necessary Constants for Both Module A and Module B\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ppm             = 1e6\n",
    "y,x             = 0,1\n",
    "\n",
    "yguess, xguess  = 160., 167. # Specific to JWST WLP Test Data\n",
    "filetype        = 'slp.fits' # Specific to JWST WLP Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Stored Instance from Save Files\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir     = '/path/to/fits/files/main/directory/'\n",
    "fitsFileDir = 'path/to/fits/subdirectories/'\n",
    "\n",
    "loadfitsdir = dataDir + fitsFileDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "method = 'mean'\n",
    "example_wanderer_mean = wanderer(fitsFileDir=loadfitsdir, filetype=filetype, \n",
    "                                            yguess=yguess, xguess=xguess, method=method)\n",
    "\n",
    "example_wanderer_mean.load_data_from_save_files(savefiledir='./SaveFiles/', \n",
    "                                                     saveFileNameHeader='Example_Wanderer_Mean_', saveFileType='.pickle.save')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "method = 'median'\n",
    "example_wanderer_median = wanderer(fitsFileDir=loadfitsdir_ModA, filetype=filetype, \n",
    "                                            yguess=yguess, xguess=xguess, method=method)\n",
    "\n",
    "example_wanderer_median.load_data_from_save_files(savefiledir='./SaveFiles/', saveFileNameHeader='Example_Wanderer_Median_', saveFileType='.pickle.save')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a New Instance with Median for the Metric\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataDir     = '/path/to/fits/files/main/directory/'\n",
    "fitsFileDir = 'path/to/fits/subdirectories/'\n",
    "\n",
    "loadfitsdir = dataDir + fitsFileDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "method = 'median'\n",
    "\n",
    "print('Initialize an instance of `wanderer` as `nircamTSOmedian_ModB`\\n')\n",
    "example_wanderer_median = wanderer(fitsFileDir=loadfitsdir_ModB, filetype=filetype, \n",
    "                                            yguess=yguess, xguess=xguess, method=method)\n",
    "\n",
    "print('Load Data From Fits Files in ' + fitsFileDir_ModB + '\\n')\n",
    "example_wanderer_median.load_data_from_fits_files()\n",
    "\n",
    "print('Skipping Load Data From Save Files in ' + fitsFileDir_ModB + '\\n')\n",
    "# example_wanderer_median.load_data_from_save_files()\n",
    "\n",
    "print('Find, flag, and NaN the \"Bad Pixels\" Outliers' + '\\n')\n",
    "example_wanderer_median.find_bad_pixels()\n",
    "\n",
    "print('Fit for All Centers: Flux Weighted, Gaussian Fitting, Gaussian Moments, Least Asymmetry' + '\\n')\n",
    "# example_wanderer_median.fit_gaussian_fitting_centering()\n",
    "# example_wanderer_median.fit_flux_weighted_centering()\n",
    "# example_wanderer_median.fit_least_asymmetry_centering()\n",
    "example_wanderer_median.fit_all_centering()\n",
    "\n",
    "print('Measure Background Estimates with All Methods: Circle Masked, Annular Masked, KDE Mode, Median Masked' + '\\n')\n",
    "# example_wanderer_median.measure_background_circle_masked()\n",
    "# example_wanderer_median.measure_background_annular_mask()\n",
    "# example_wanderer_median.measure_background_KDE_Mode()\n",
    "# example_wanderer_median.measure_background_median_masked()\n",
    "example_wanderer_median.measure_all_background()\n",
    "\n",
    "print('Iterating over Background Techniques, Centering Techniques, Aperture Radii' + '\\n')\n",
    "background_choices = example_wanderer_median.background_df.columns\n",
    "centering_choices  = ['Gaussian_Fit', 'Gaussian_Mom', 'FluxWeighted', 'LeastAsymmetry']\n",
    "aperRads           = np.arange(1, 100.5,0.5)\n",
    "\n",
    "start = time()\n",
    "for bgNow in background_choices:\n",
    "    for ctrNow in centering_choices:\n",
    "        for aperRad in aperRads:\n",
    "            print('Working on Background ' + bgNow + ' with Centering ' + ctrNow + ' and AperRad ' + str(aperRad), end=\" \")\n",
    "            example_wanderer_median.compute_flux_over_time(aperRad=aperRad, centering=ctrNow, background=bgNow)\n",
    "            flux_key_now  = ctrNow + '_' + bgNow+'_' + 'rad' + '_' + str(aperRad)\n",
    "            print(std(example_wanderer_median.flux_TSO_df[flux_key_now] / median(nircamTSOmedian_ModB.flux_TSO_df[flux_key_now]))*ppm)\n",
    "\n",
    "print('Operation took: ', time()-start)\n",
    "\n",
    "print('Saving `example_wanderer_median` to a set of pickles for various Image Cubes and the Storage Dictionary')\n",
    "example_wanderer_median.save_data_to_save_files(savefiledir='./SaveFiles/', saveFileNameHeader='Example_Wanderer_Median_', saveFileType='.pickle.save')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a New Instance with Mean for the Metric\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "method = 'mean'\n",
    "\n",
    "print('Initialize an instance of `wanderer` as `example_wanderer_mean`')\n",
    "example_wanderer_mean = wanderer(fitsFileDir=loadfitsdir_ModB, filetype = filetype, \n",
    "                                yguess=yguess, xguess=xguess, method=method)\n",
    "\n",
    "print('Load Data From Fits Files in ' + loadfitsdir)\n",
    "example_wanderer_mean.load_data_from_fits_files()\n",
    "\n",
    "print('Skipping Load Data From Save Files in ' + loadfitsdir)\n",
    "# nircamTSOmean_ModB.load_data_from_save_files()\n",
    "\n",
    "print('Find, flag, and NaN the \"Bad Pixels\" Outliers')\n",
    "example_wanderer_mean.find_bad_pixels()\n",
    "\n",
    "print('Fit for All Centers: Flux Weighted, Gaussian Fitting, Gaussian Moments, Least Asymmetry')\n",
    "# example_wanderer_mean.fit_gaussian_fitting_centering()\n",
    "# example_wanderer_mean.fit_flux_weighted_centering()\n",
    "# example_wanderer_mean.fit_least_asymmetry_centering()\n",
    "example_wanderer_mean.fit_all_centering()\n",
    "\n",
    "print('Measure Background Estimates with All Methods: Circle Masked, Annular Masked, KDE Mode, Median Masked')\n",
    "# example_wanderer_mean.measure_background_circle_masked()\n",
    "# example_wanderer_mean.measure_background_annular_mask()\n",
    "# example_wanderer_mean.measure_background_KDE_Mode()\n",
    "# example_wanderer_mean.measure_background_median_masked()\n",
    "example_wanderer_mean.measure_all_background()\n",
    "\n",
    "print('Iterating over Background Techniques, Centering Techniques, Aperture Radii')\n",
    "background_choices = example_wanderer_mean.background_df.columns\n",
    "centering_choices  = ['Gaussian_Fit', 'Gaussian_Mom', 'FluxWeighted', 'LeastAsymmetry']\n",
    "aperRads           = np.arange(1, 100.5,0.5)\n",
    "\n",
    "start = time()\n",
    "for bgNow in background_choices:\n",
    "    for ctrNow in centering_choices:\n",
    "        for aperRad in aperRads:\n",
    "            print('Working on Background ' + bgNow + ' with Centering ' + ctrNow + ' and AperRad ' + str(aperRad), end=\" \")\n",
    "            example_wanderer_mean.compute_flux_over_time(aperRad=aperRad, centering=ctrNow, background=bgNow)\n",
    "            flux_key_now  = ctrNow + '_' + bgNow+'_' + 'rad' + '_' + str(aperRad)\n",
    "            print(std(example_wanderer_mean.flux_TSO_df[flux_key_now] / median(example_wanderer_mean.flux_TSO_df[flux_key_now]))*ppm)\n",
    "\n",
    "print('Operation took: ', time()-start)\n",
    "\n",
    "print('Saving `example_wanderer_mean` to a set of pickles for various Image Cubes and the Storage Dictionary')\n",
    "example_wanderer_mean.save_data_to_save_files(savefiledir='./SaveFiles/', saveFileNameHeader='Example_Wanderer_Mean_', saveFileType='.pickle.save')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
